import {Breadcrumb, Col, Row, Typography} from 'antd';
import React from 'react';
import {contentStyle} from "../SiderStaticMenu.js";
import Image from "next/image";
import {downloadFile} from "../../util";


export default function ManualMapping() {
    const downloadCounts = () => {
        downloadFile(`/api/submitted-files/counts/c71959a0-6a62-11ed-a471-a39e452631de`)
    }
    const downloadLabels = () => {
        downloadFile(`/api/submitted-files/counts/c71959a0-6a62-11ed-a471-a39e452631de`)
    }
    return (
        <div className="modal-body-stw" style={contentStyle}>
            <Breadcrumb>
                <Breadcrumb.Item>Help</Breadcrumb.Item>
                <Breadcrumb.Item>Manual</Breadcrumb.Item>
                <Breadcrumb.Item>Spatial Mapping</Breadcrumb.Item>
            </Breadcrumb>
            <Typography style={{marginTop:50,fontSize:16}}>
                <h1>Spatial Mapping</h1>
                <h2>1. Introduction</h2>
                <p style={{fontSize:16}}> This Module allows users to utilize multiple machine learning methods to map cell labels
                    in scRNA-seq data back to the spatial transcriptome to see the distribution of cell labels in the spatial transcriptome data.
                    It presents the predicted spatial distribution of cell labels by scRNA-seq came from users, which may provide a new
                    dimensional perspective to explore the scRNA-seq datasets.
                </p>
                <h2>2. Reference Data</h2>
                <h2>3. Methods</h2>
                <h3>(1) Tangram </h3>
                <p>Tangram, an algorithm that uses sc/snRNA-seq data as &apos;puzzle pieces&apos; to align in space to match
                    &apos;the shape&apos; of the spatial data (Fig. 1a). The input to Tangram is sc/snRNA-seq data along with
                    spatial profiling data from the same region or tissue type, from any currently available spatial
                    method (for example MERFISH, smFISH, STARmap, ISH, or Visium), requiring only that the two modalities
                    share at least some subset of common genes.</p>
                <p>
                    <i>- Biancalani, T., Scalia, G., Buffoni, L. et al. Deep learning and alignment of spatially resolved
                    single-cell transcriptomes with Tangram. Nat Methods 18, 1352–1362 (2021). </i>
                    <a href={"https://doi.org/10.1038/s41592-021-01264-7"} target={"_blank"} rel={"noreferrer"}>
                    https://doi.org/10.1038/s41592-021-01264-7</a>
                </p>
                <h3>(2) Cell2location </h3>
                <h2>4. Format of Uploaded Files</h2>
                <a id={"format_uploaded_files"} style={{position: 'relative', top: "-150px"}}></a>
                <h3>(1) Count Matrix File </h3>
                <span>
                    This file contains gene expression <b>(raw counts)</b> values in which <b>columns are genes </b>
                    presented with gene names identifier (HGNC symbol name) and
                    <b> rows are cells</b> presented with cell IDs. Formats accepted are .csv, .tsv and .txt
                    in .gz/zip compression.
                </span><br/>
                <span>&gt; Example:</span><br/>
                <Image src={`/images/counts_matrix_example.png`} alt="..." width={400} height={220}/>
                <p>
                    <a onClick={downloadCounts}>Download an example count file</a>
                </p>
                <h3>(2) Label File </h3>
                <span>
                    This file is generated by users after assigning cell type identity to clusters in scRNA-seq analysis.
                    The file must contain <b>two necessary columns</b>: 1) the first column must be the unique
                    <b> &quot;cell_id&quot; </b>in line with count matrix file;
                    2) the column indicating cell type identity must be titled with <b>&quot;cell_type&quot;</b>.
                    Formats accepted are .csv, .tsv and .txt in .gz/zip compression.
                </span><br/>
                <span>&gt; Example:</span><br/>
                <Image src={`/images/labels_example.png`} alt="..." width={400} height={130}/>
                <p>
                    <a onClick={downloadLabels}>Download an example label file</a>
                </p>
                <h2>5. Mapping Result</h2>
                <a id={"mapping_result"} style={{position: 'relative', top: "-150px"}}></a>
                <h3>(1) Preprocessing </h3>
                <a id={"preprocessing"} style={{position: 'relative', top: "-150px"}}></a>
                <h3>(2) Filtering </h3>
                <a id={"filtering"} style={{position: 'relative', top: "-150px"}}></a>
                <h3>(3) Spatial Niche </h3>
                <a id={"spatial_niche"} style={{position: 'relative', top: "-150px"}}></a>
                <h3>(4) Cell Types Colocalization </h3>
                <a id={"colocalization"} style={{position: 'relative', top: "-150px"}}></a>
                <p>After obtaining the predicted spatial coordinates, we can estimate the spatial distance and
                    recapitulate the colocalization of different cell types by this module. </p>
                <h4>Methods:</h4>
                <p>
                    <b>(1)</b> Firstly, we calculate a <b>2D grid kernel density</b> for each cell type by KernelDensity function
                    from <b>sklearn.neighbor</b> Python package with gaussian kernel and user-defined parameter
                    <b><i> bandwidth </i></b>associated with ST spots density and kernel smoothness. Then we calculate predicted
                    <b> appearance probability</b> for each cell type over a 2d grid of points evenly with 100 points in each direction.
                    <br/>
                    <b>(2)</b> Secondly, we calculate the <b>divergence between appearance probabilities of two cell types </b>
                    over these 10000 points to estimate their spatial proximity. The method to calculate divergence is
                    <b> Jensen-Shannon divergence (JS Divergence)</b>, which is based on the <b>Kullback–Leibler divergence (KL Divergence)</b>
                        , with some notable differences, including that it is symmetric.
                    <br/>It is defined by
                </p>
                <Image src={"/images/help/jsd.png"} height={50} width={400}/>
                <br/><span>where</span><br/>
                <Image src={"/images/help/kld.png"} height={50} width={230}/>
                <Image src={"/images/help/m.png"} height={50} width={120}/>
                <p>
                    <b>(3)</b> Thirdly, based on the <b>negative log2 JS divergence </b>matrix of different cell type,
                    we construct a <b>maximum spanning tree (MST)</b> to present the simplified cell types colocalization
                    by <b>networkx</b> Python package with edge
                    <br/><b>(4)</b> To estimate the complete cell types colocalization, the above calculation steps are
                    performed repetitively on <b>bootstrapping samples</b> (default 80 percentage samples and  20 iterations)
                    to generate an <b>average negative log2 JS divergence matrix</b> (visualized as heatmap graph 5.4.1)
                    and an <b>average MST consensus matrix</b> visualized into network graph (visualized as network graph 5.4.2).
                    <br/><b>(5)</b> Finally, we retain the some the most proximal cell type pairs referring to
                    user-defined parameter <b><i>cutoff</i></b> equal to percentage of top retained colocalization relation
                    of cell type pairs according to MST consensus matrix, and then extract microenvirionments for each cell
                    type assigning a name <b>“Microenv_[central cell type]”</b>  whose [central cell type] means
                    the cell type closing to all other cell types in this microenvirionment. Therefore some cell types
                    will occur repetitively in some microenvirionment but with different biological functioning.
                </p>
                <h4>Graph:</h4>
                <p>
                    In JS divergence matrix graph , darker the box, the greater the value on behalf of mean -log2 JSD
                    from 20 times bootstrapping samples indicating global closeness. In MST graph, nodes represent cell
                    types, which are darker and larger with more colocalization relationship, and edges represent
                    colocalization of two cell types, which are darker and wider with higher proximity.
                </p>
                <Row justify={"center"} style={{textAlign:"center",color:"gray"}}>
                    <Col span={12}>
                        <Image src={"/images/help/JSDM.png"} height={400} width={400}/>
                        <p>graph 5.4.1</p>
                    </Col>
                    <Col span={12}>
                        <Image src={"/images/help/MST.png"} height={400} width={400}/>
                        <p>graph 5.4.2</p>
                    </Col>
                </Row>
                <h4>(5) Cell-Cell Interactions </h4>
                <a id={"interaction"} style={{position: 'relative', top: "-150px"}}></a>
                <h4>(6) Result Files Download </h4>
                <a id={"download"} style={{position: 'relative', top: "-150px"}}></a>
            </Typography>
        </div>
    )
}